# -*- coding: utf-8 -*-
"""playerml (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-wm6jnQLZFvxQ7d_JU2Xp3DKoIsCEMGD
"""

import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.utils import image_dataset_from_directory

"""## Load Data
We first load the training, test and validation datasets into a `tf.data.Dataset` helper to facilitate caching, prefetching and conversions. Our data consists of 13 classes: pawn, rook, bishop, knight, queen and king in both white and black (12 classes) plus one class for an empty square (no piece). The dataset consists of 2406 total images.
"""

ds_train = image_dataset_from_directory(
    "../input/data-train/train",
    labels="inferred",
    label_mode="categorical",
    image_size=[224, 224],
    interpolation="nearest",
    batch_size=32,
    shuffle=True,
)

ds_test = image_dataset_from_directory(
    "../input/data-test/test",
    labels="inferred",
    label_mode="categorical",
    image_size=[224, 224],
    interpolation="nearest",
    batch_size=32,
    shuffle=True,
)

ds_val = image_dataset_from_directory(
    "../input/data-valid/valid",
    labels="inferred",
    label_mode="categorical",
    image_size=[224, 224],
    interpolation="nearest",
    batch_size=32,
    shuffle=False,
)

"""## Transform Data
Here, we use a `convert_to_float` helper function to convert the dataset from ints to floats for consistency and higher precision. We also use the `cache` function to load the images from memory after the first iteration for quicker training and improved performance. We also utilize tensorflow's `AUTOTUNE` macro to automate the buffer size for prefetching.
"""

def convert_to_float(image, label):
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    return image, label

AUTOTUNE = tf.data.experimental.AUTOTUNE
ds_train = ds_train.map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)
ds_test = ds_test.map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)
ds_val = ds_val.map(convert_to_float).cache().prefetch(buffer_size=AUTOTUNE)

"""## Data Augmentation
Our dataset is quite small, there are only roughly 2,000 training images. We will use a data augmentation technique to increase the number of images and improve our performance model. Here, we choose practical transformations that would result in realistic chess piece positions. For example, horizontal flipping, blurring, and random translations. We do not use rotations or vertical flips here, as it would not make sense for pieces to be upside down or heavily rotated.
"""

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),
    tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.5),
    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),
])

"""## Transfer Learning
Typically during CNN model creation, we leverage the capabilities of a pre-trained model and enhance it with trainable convolution layers and the classification head. I will follow this model and leverage transfer learning on the pre-trained base **VGG16** model from Keras. We will include one Convolutional layer to train specifically on our dataset. Looking at the VGG16 model below, we can see it has 13 convolutional layers, 5 max pooling layers and 3 fully connected layers, trained on a total of 15 million images. This is likely to increase our performance substantially.
"""

from tensorflow.keras.applications.vgg16 import VGG16

model_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
model_base.trainable = False
model_base.summary()

"""## Model Head
Now, we can define our model head which will bne trained on our data. I define the following architecture:
- A data augmentation layer to generate transformed images to prevent overfitting
- The VGG16 base model which is not trainable

- A 2D Convolutional layer to be trained on our dataset (includes batch normalization to reduce training time)

- A Global max pooling layer to flatten the outputs before feeding to the classification head

- A fully connected Dense layer of 128 neurons
- A dropout layer to prevent overfitting
- A final Dense layer with a softmax activation to classify into one of the 13 classes
"""

from tensorflow.keras import layers

model = tf.keras.Sequential([
    data_augmentation,
    model_base,

    layers.BatchNormalization(),

    # conv layer 1
    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),
    layers.BatchNormalization(),

    # conv layer 2
    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),
    layers.BatchNormalization(),

    tf.keras.layers.GlobalMaxPooling2D(),
    layers.Dropout(0.4),

    # Output
    layers.Dense(13, activation='softmax'),
])

"""## Early Stopping
To prevent overfitting of our model, we define an early stopping callback. This is helpful to stop the model early when the validation loss is not decreasing anymore. We select `min_delta=0.001` as the threshold for imporvement, and we define `patience=20` to stop the model when there is no more deterioration in loss after 20 epochs.

## Optimizer and Loss Function
We choose the Adam optimizer as an adaptive gradient descent method which is the standard for computer vision tasks and performs well. We also select Categorical Cross Entropy as our loss function, since we have more than 2 categories (so binary cross entropy does not work here).
"""

early_stopping = tf.keras.callbacks.EarlyStopping(
    min_delta=0.001,
    patience=20,
    restore_best_weights=True,
)

# compile model
model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=['accuracy'],
)

history = model.fit(
    ds_train,
    epochs=300,
    validation_data=ds_val,
    callbacks=[early_stopping],
)

import pandas as pd

history_df = pd.DataFrame(history.history)

history_df.loc[:, ['loss', 'val_loss']].plot()
plt.title("Model Loss")
plt.ylabel("Loss")
plt.xlabel("Epoch")
plt.legend(["Training Loss", "Validation Loss"])

history_df.loc[:, ['accuracy', 'val_accuracy']].plot();
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Training Accuracy', 'Validation Accuracy'])
plt.show()

"""## Confusion Matrix and F1 Score
We will now plot a confusion matrix of the model's predictions to visualize the performance of our model on the test dataset.
"""

import numpy as np
import seaborn as sns
from sklearn.metrics import confusion_matrix

def labels_from_dataset(dataset: tf.data.Dataset, batched: bool = False):
    labels = list(map(lambda x: x[1], dataset))
    return tf.concat(labels, axis=0)

labels = labels_from_dataset(ds_test)
predictions = model.predict(ds_test)

y_predictions = np.argmax(predictions, axis=1)
y_true = np.argmax(labels, axis=1)

conf_matrix = confusion_matrix(y_predictions, y_true)

print(conf_matrix)

# plot with seaborn
class_names = ['bb', 'bk', "bn", "bp", "bq", "br", "empty", "wb", "wk", "wn", "wp", "wq", "wr"]

plt.figure(figsize=(15, 7.5))
ax = plt.subplot()
sns.heatmap(conf_matrix, cmap="Blues", annot=True, ax=ax)

ax.set_xlabel("Predicted Classes")
ax.set_ylabel("True Classes")
ax.set_title("Confusion Matrix - Test Dataset")
ax.xaxis.set_ticklabels(class_names)
ax.yaxis.set_ticklabels(class_names)

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from tabulate import tabulate

report = classification_report(
    y_true, y_predictions,
    target_names=class_names,
    digits=3
)

# show nice table with tabulate
report_data = []
lines = report.split('\n')
for line in lines[2:-3]:
    row = line.split()
    report_data.append(row)

table = tabulate(report_data, headers=['Class', 'Precision', 'Recall', 'F1-Score', 'Support'], tablefmt='grid')
print(table)

accuracy = accuracy_score(y_true, y_predictions)
print(f"Total Accuracy: {accuracy}")

model.save('/kaggle/working/chess_model.h5')  # Save the whole model

"""## Evaluating Performance
The classifier seems to perform well across most classes, with high precision, recall, and F1-scores for many classes.

Some classes, such as 'wb', 'wk', and 'wp', show slightly lower scores, indicating potential challenges in correctly classifying these instances.

The overall accuracy is 91.9%, suggesting that the model is effective in making correct predictions across all classes.

The macro and weighted averages are close to each other, indicating a balanced performance across different classes.

## TODO
Take a couple hundred pictures of chess pieces in real life and use my model on these pictures, to see how well it performs in the real world.
"""

from tensorflow.keras.models import load_model

# Load your model from the Kaggle input path
model_path = '/kaggle/input/chess_model/tensorflow2/default/1/chess_model.h5'
model = load_model(model_path)

print("‚úÖ Model loaded successfully!")

from tensorflow.keras.models import load_model
import numpy as np
import cv2
import matplotlib.pyplot as plt

# Load and preprocess the chessboard image
img = cv2.imread('/kaggle/input/chess-board/board1.jpg')
img_resized = cv2.resize(img, (224, 224))  # Change size if your model expects a different input
img_input = img_resized / 255.0
img_input = np.expand_dims(img_input, axis=0)

# Run prediction
prediction = model.predict(img_input)
predicted_class = np.argmax(prediction)

# Define the class labels (update if different)
class_names = ['empty', 'white_king', 'white_queen', 'white_rook', 'white_bishop',
               'white_knight', 'white_pawn', 'black_king', 'black_queen', 'black_rook',
               'black_bishop', 'black_knight', 'black_pawn']

print(f"üîç Detected piece: {class_names[predicted_class]}")

# Show the image
plt.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))
plt.title(f"Prediction: {class_names[predicted_class]}")
plt.axis('off')
plt.show()

import tensorflow as tf
from tensorflow.keras.models import load_model
import numpy as np
import cv2
import os
from PIL import Image
import matplotlib.pyplot as plt

# Load your model
model_path = '/kaggle/input/chess_model/tensorflow2/default/1/chess_model.h5'
model = load_model(model_path)

label_map = {
    0: "Empty",
    1: "White Pawn", 2: "White Rook", 3: "White Knight", 4: "White Bishop", 5: "White Queen", 6: "White King",
    7: "Black Pawn", 8: "Black Rook", 9: "Black Knight", 10: "Black Bishop", 11: "Black Queen", 12: "Black King"
}

import cv2
import numpy as np

def extract_squares(image_path):
    img = cv2.imread(image_path)
    img = cv2.resize(img, (224, 224))
    square_size = 28
    squares = []

    for row in range(8):
        for col in range(8):
            square = img[row*square_size:(row+1)*square_size, col*square_size:(col+1)*square_size]
            square_resized = cv2.resize(square, (224, 224))  # Match model input size
            square_resized = square_resized / 255.0
            squares.append(square_resized)

    return np.array(squares)  # Shape: (64, 224, 224, 3)

def predict_pieces(model, squares):
    predictions = []

    for square in squares:
        square = np.expand_dims(square, axis=0)  # Shape: (1, 224, 224, 3)
        pred = model.predict(square)
        pred_class = np.argmax(pred, axis=1)[0]
        predictions.append(pred_class)

    return np.array(predictions).reshape(8, 8)  # Shape: (8x8 chessboard)

material_score = {
    "White Pawn": 1, "White Knight": 3, "White Bishop": 3, "White Rook": 5, "White Queen": 9,
    "Black Pawn": 1, "Black Knight": 3, "Black Bishop": 3, "Black Rook": 5, "Black Queen": 9,
    "White King": 0, "Black King": 0, "Empty": 0
}

def calculate_score(predicted_board):
    white_total, black_total = 0, 0

    for row in predicted_board:
        for cls in row:
            label = label_map[cls]
            if "White" in label:
                white_total += material_score.get(label, 0)
            elif "Black" in label:
                black_total += material_score.get(label, 0)

    leader = "White" if white_total > black_total else "Black" if black_total > white_total else "Equal"
    diff = abs(white_total - black_total)

    return leader, diff, white_total, black_total

# Example usage
image_path = "/kaggle/input/chess-board/board1.jpg"

squares = extract_squares(image_path)
predicted_board = predict_pieces(model, squares)
leader, diff, white_score, black_score = calculate_score(predicted_board)

print(f"White Score: {white_score}, Black Score: {black_score}")
print(f"{leader} is leading by {diff} points")

import google.generativeai as genai
from PIL import Image
import json
import re

# Configure Gemini
genai.configure(api_key="AIzaSyD_ttXOxFAW6KTEzMWz8QyEcdH9cWUza-k")
model = genai.GenerativeModel("gemini-2.0-flash-exp")

def get_gemini_insight(image_path):
    image = Image.open(image_path).convert("RGB")

    prompt = """
You are a chess engine assistant. Given the image of a chess board, analyze it and provide this output in pure JSON format:

{
  "leader": "<White/Black/Equal>",
  "white_score": <int>,
  "black_score": <int>,
  "leading_by": <int>,
  "suggestion": "<1-2 sentence strategic advice>"
}

Examples:

Example 1:
Board: White has all pieces, Black lost queen and rook
Output:
{
  "leader": "White",
  "white_score": 38,
  "black_score": 24,
  "leading_by": 14,
  "suggestion": "White should trade pieces and simplify into a winning endgame."
}

Example 2:
Board: Black has queen and 2 rooks, White lost both rooks
Output:
{
  "leader": "Black",
  "white_score": 26,
  "black_score": 36,
  "leading_by": 10,
  "suggestion": "Black should maintain pressure and avoid unnecessary trades."
}

Now analyze this board and return only the JSON:
"""

    response = model.generate_content([prompt, image])

    # Remove triple backticks if present
    clean_response = re.sub(r"```json|```", "", response.text).strip()

    try:
        return json.loads(clean_response)
    except Exception as e:
        print("‚ö†Ô∏è Could not parse Gemini's output. Raw response:")
        print(response.text)
        return {
            "leader": "Unknown",
            "white_score": 0,
            "black_score": 0,
            "leading_by": 0,
            "suggestion": "Parsing failed. Check board clarity."
        }

insight = get_gemini_insight("/kaggle/input/chess-board/board1.jpg")
print("Strategic JSON Insight:")
print(json.dumps(insight, indent=2))

